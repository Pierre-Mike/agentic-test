name: Issue Confidence Assessment
description: Assess issues for auto-implementation confidence

on:
  issues:
    types: [opened]

concurrency:
  group: issue-${{ github.event.issue.number }}
  cancel-in-progress: false

jobs:
  assess-confidence:
    runs-on: ubuntu-latest
    timeout-minutes: 5
    permissions:
      contents: read
      issues: write

    steps:
      - name: Checkout repository
        uses: actions/checkout@v5
        with:
          fetch-depth: 0

      - name: Run Confidence Assessment
        uses: anthropics/claude-code-action@main
        with:
          prompt: "/assess-confidence ${{ github.event.issue.number }}"
          claude_code_oauth_token: ${{ secrets.CLAUDE_CODE_OAUTH_TOKEN }}
          allowed_non_write_users: "*"
          github_token: ${{ secrets.GITHUB_TOKEN }}
          model: sonnet
          timeout: 180000

      - name: Handle Assessment Failure
        if: failure()
        uses: actions/github-script@v7
        with:
          script: |
            await github.rest.issues.addLabels({
              owner: context.repo.owner,
              repo: context.repo.repo,
              issue_number: context.payload.issue.number,
              labels: ['needs-review']
            });
            await github.rest.issues.createComment({
              owner: context.repo.owner,
              repo: context.repo.repo,
              issue_number: context.payload.issue.number,
              body: '## Confidence Assessment Failed\n\nThe automated confidence assessment encountered an error. This issue has been flagged for human review.\n\n*A maintainer can add the `auto-implement` label manually if appropriate.*'
            });
